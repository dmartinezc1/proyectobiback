{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerias\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 25) # Número máximo de columnas a mostrar\n",
    "pd.set_option('display.max_rows', 50) # Numero máximo de filas a mostar\n",
    "import numpy as np\n",
    "np.random.seed(3301)\n",
    "import pandas as pd\n",
    "# Para preparar los datos\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Para crear el arbol de decisión \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Para realizar la separación del conjunto de aprendizaje en entrenamiento y test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Para evaluar el modelo\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# Para búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Para la validación cruzada\n",
    "from sklearn.model_selection import KFold \n",
    "#Librerías para la visualización\n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "from sklearn import tree\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # Plot utility\n",
    "from sklearn.utils import shuffle # to shuffle the data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "#from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "\n",
    "df_original = pd.read_csv('MovieReviews.csv', sep=\",\",encoding='utf-8', index_col=0) \n",
    "df = df_original.copy()\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentimiento'] = df['sentimiento'].replace({'negativo':0, 'positivo':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.title(\"Número de valores positivos y negativos de sentimiento\")\n",
    "plot = sn.countplot(x='sentimiento', data=df)\n",
    "for p in plot.patches:\n",
    "    plot.annotate(p.get_height(), (p.get_x() + 0.1, p.get_height() + 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "# Create a new column 'language' in the dataframe\n",
    "df['language'] = df['review_es'].apply(lambda x: detect(x))\n",
    "# Print the number of reviews in each language\n",
    "print(df['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language'] == 'es'].drop(columns=['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.title(\"Número de valores positivos y negativos de sentimiento\")\n",
    "plot = sn.countplot(x='sentimiento', data=df)\n",
    "for p in plot.patches:\n",
    "    plot.annotate(p.get_height(), (p.get_x() + 0.1, p.get_height() + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = df.loc[df['sentimiento'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['sentimiento'].value_counts(dropna = False, normalize = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_df['review_es'], reviews_df['sentimiento'], test_size = 0.3, stratify = reviews_df['sentimiento'], random_state = 42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de las palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(words):\n",
    "    return nltk.word_tokenize(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(tokenize)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de valores no deseados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_markup(words):\n",
    "    words_ok = []\n",
    "    for word in words:\n",
    "        word = re.sub('(<.*?>)',' ', str(word))\n",
    "        word = re.sub('\\[[^]]*\\]', ' ', word)\n",
    "        words_ok.append(word)\n",
    "    return words_ok\n",
    "        \n",
    "    \n",
    "def remove_short_words(words):\n",
    "    words_ok = []\n",
    "    for word in words:\n",
    "        if len(word) > 1: #Only words with size>1\n",
    "            words_ok.append(re.sub('[^A-Za-z]+','',str(word)))\n",
    "    return words_ok\n",
    "def replace_numbers(words):\n",
    "    p = inflect.engine()\n",
    "    words_ok = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            if word.isdigit():\n",
    "                words_ok.append(p.number_to_words(word))\n",
    "            else:\n",
    "                words_ok.append(word)\n",
    "        except:\n",
    "            print('[ERROR: word numOutOfRangeError...]'+str(word))#special cases with large numbers\n",
    "            pass\n",
    "    return words_ok\n",
    "\n",
    "def remove_stop_words(words):\n",
    "    stopWords = set(stopwords.words('spanish'))\n",
    "    words_ok = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            words_ok.append(w)\n",
    "    return words_ok\n",
    "\n",
    "def preprocess_words(words):\n",
    "    temp = remove_short_words(words)\n",
    "    temp = replace_numbers(temp)\n",
    "    temp = remove_stop_words(temp)\n",
    "    temp = remove_markup(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(preprocess_words)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemmas.append(lemmatizer.lemmatize(word))\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lemmatize) \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: ' '.join(map(str, x)))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfIdVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "print(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "modeloRF = RandomForestClassifier(n_estimators=1200)\n",
    "modeloRF.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_train_pred = modeloRF.predict(X_train_tfidf)\n",
    "y_test_pred = modeloRF.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de metricas\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "f1_test =f1_score(y_test, y_test_pred)\n",
    "\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitud en entrenamiento: \"+str(accuracy_train))\n",
    "print(\"Exactitud en prueba: \"+str(accuracy_test))\n",
    "\n",
    "print(\"F1 en entrenamiento: \"+str(f1_train))\n",
    "print(\"F1 en prueba: \"+str(f1_test))\n",
    "\n",
    "print(\"Recall en entrenamiento: \"+str(recall_train))\n",
    "print(\"Recall en prueba: \"+str(recall_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Almacenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump((modeloRF,tfidf_vectorizer), \"./app/random_forest.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
